version: '3.4'

services:
  namenode:
    image: fixcer/namenode
    container_name: namenode
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env
    ports:
      - '9870:9870'
    networks:
      - net

  resourcemanager:
    image: fixcer/resourcemanager
    container_name: resourcemanager
    restart: on-failure
    depends_on:
      - namenode
      - datanode1
      - datanode2
      - datanode3
    env_file:
      - ./hadoop.env
    ports:
      - '8089:8088'
    networks:
      - net

  historyserver:
    image: fixcer/historyserver
    container_name: historyserver
    depends_on:
      - namenode
      - datanode1
      - datanode2
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env
    ports:
      - '8188:8188'
    networks:
      - net

  nodemanager:
    image: fixcer/nodemanager
    container_name: nodemanager
    depends_on:
      - namenode
      - datanode1
      - datanode2
    env_file:
      - ./hadoop.env
    ports:
      - '8042:8042'
    networks:
      - net

  datanode1:
    image: fixcer/datanode
    container_name: datanode1
    depends_on:
      - namenode
    volumes:
      - hadoop_datanode1:/hadoop/dfs/data
    env_file:
      - ./hadoop.env
    networks:
      - net

  datanode2:
    image: fixcer/datanode
    container_name: datanode2
    depends_on:
      - namenode
    volumes:
      - hadoop_datanode2:/hadoop/dfs/data
    env_file:
      - ./hadoop.env
    networks:
      - net

  datanode3:
    image: fixcer/datanode
    container_name: datanode3
    depends_on:
      - namenode
    volumes:
      - hadoop_datanode3:/hadoop/dfs/data
    env_file:
      - ./hadoop.env
    networks:
      - net

  spark-master:
    image: fixcer/spark-master
    container_name: spark_master
    ports:
      - 8080:8080
      - 7077:7077
    env_file:
      - ./hadoop.env
    environment:
      - PYSPARK_PYTHON=python3
      - PYSPARK_DRIVER_PYTHON=python3
      - INIT_DAEMON_STEP=setup_spark
    networks:
      - net

  spark-worker:
    image: fixcer/spark-worker
    container_name: spark_worker
    depends_on:
      - spark-master
    env_file:
      - ./hadoop.env
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - PYSPARK_PYTHON=python3
      - PYSPARK_DRIVER_PYTHON=python3
    ports:
      - 8081:8081
    networks:
      - net

  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    expose:
      - '2181'
    ports:
      - 2181:2181
    networks:
      - net

  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    expose:
      - '9092'
    ports:
      - 9092:9092
    links:
      - zookeeper
    depends_on:
      - zookeeper
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_PORT: 9092
      KAFKA_ADVERTISED_HOST_NAME: kafka
      KAFKA_ADVERTISED_LISTENERS: INSIDE://:9092,OUTSIDE://localhost:19092
      KAFKA_LISTENERS: INSIDE://:9092,OUTSIDE://0.0.0.0:19092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
    networks:
      - net

  kafka_manager:
    image: hlebalbau/kafka-manager:1.3.3.18
    container_name: kafka_manager
    expose:
      - '9000'
    ports:
      - 9000:9000
    environment:
      ZK_HOSTS: 'zookeeper:2181'
      APPLICATION_SECRET: 'random-secret'
      command: -Dpidfile.path=/dev/null
    links:
      - kafka
      - zookeeper
    depends_on:
      - 'zookeeper'
      - 'kafka'
    networks:
      - net

  hue:
    image: gethue/hue
    container_name: hue
    ports:
      - '8088:8888'
    env_file:
      - ./hadoop.env
    volumes:
      - ./hue.ini:/usr/share/hue/desktop/conf/hue-overrides.ini
    depends_on:
      - namenode
    networks:
      - net

  ## Mongo Cluster

  ## Router
  router01:
    image: mongo
    container_name: router01
    command: mongos --port 27017 --configdb rs-config-server/configsvr01:27017,configsvr02:27017,configsvr03:27017 --bind_ip_all
    ports:
      - 27017:27017
    volumes:
      - ./scripts:/scripts
      - data_router01:/data/db
    networks:
      - net

  router02:
    image: mongo
    container_name: router02
    command: mongos --port 27017 --configdb rs-config-server/configsvr01:27017,configsvr02:27017,configsvr03:27017 --bind_ip_all
    volumes:
      - ./scripts:/scripts
      - data_router02:/data/db
    ports:
      - 27018:27017
    links:
      - router01
    networks:
      - net

  ## Config Servers
  configsvr01:
    image: mongo
    container_name: configsvr01
    command: mongod --port 27017 --configsvr --replSet rs-config-server
    volumes:
      - ./scripts:/scripts
      - data_configsvr01:/data/db
    ports:
      - 27019:27017
    links:
      - shard01-a
      - shard02-a
      - shard03-a
    networks:
      - net

  configsvr02:
    image: mongo
    container_name: configsvr02
    command: mongod --port 27017 --configsvr --replSet rs-config-server
    volumes:
      - ./scripts:/scripts
      - data_configsvr02:/data/db
    ports:
      - 27020:27017
    links:
      - configsvr01
    networks:
      - net

  configsvr03:
    image: mongo
    container_name: configsvr03
    command: mongod --port 27017 --configsvr --replSet rs-config-server
    volumes:
      - ./scripts:/scripts
      - data_configsvr03:/data/db
    ports:
      - 27021:27017
    links:
      - configsvr02
    networks:
      - net

  ## Shards
  shard01-a:
    image: mongo
    container_name: shard01-a
    command: mongod --port 27017 --shardsvr --replSet rs-shard-01
    volumes:
      - ./scripts:/scripts
      - data_shard01-a:/data/db
    ports:
      - 27022:27017
    links:
      - shard01-b
      - shard01-c
    networks:
      - net

  shard01-b:
    image: mongo
    container_name: shard01-b
    command: mongod --port 27017 --shardsvr --replSet rs-shard-01
    volumes:
      - ./scripts:/scripts
      - data_shard01-b:/data/db
    ports:
      - 27023:27017
    networks:
      - net

  shard01-c:
    image: mongo
    container_name: shard01-c
    command: mongod --port 27017 --shardsvr --replSet rs-shard-01
    volumes:
      - ./scripts:/scripts
      - data_shard01-c:/data/db
    ports:
      - 27024:27017
    networks:
      - net

  ## Shards 02
  shard02-a:
    image: mongo
    container_name: shard02-a
    command: mongod --port 27017 --shardsvr --replSet rs-shard-02
    volumes:
      - ./scripts:/scripts
      - data_shard02-a:/data/db
    ports:
      - 27025:27017
    links:
      - shard02-b
      - shard02-c
    networks:
      - net

  shard02-b:
    image: mongo
    container_name: shard02-b
    command: mongod --port 27017 --shardsvr --replSet rs-shard-02
    volumes:
      - ./scripts:/scripts
      - data_shard02-b:/data/db
    ports:
      - 27026:27017
    networks:
      - net

  shard02-c:
    image: mongo
    container_name: shard02-c
    command: mongod --port 27017 --shardsvr --replSet rs-shard-02
    volumes:
      - ./scripts:/scripts
      - data_shard02-c:/data/db
    ports:
      - 27027:27017
    networks:
      - net

  ## Shards 03
  shard03-a:
    image: mongo
    container_name: shard03-a
    command: mongod --port 27017 --shardsvr --replSet rs-shard-03
    volumes:
      - ./scripts:/scripts
      - data_shard03-a:/data/db
    ports:
      - 27028:27017
    links:
      - shard03-b
      - shard03-c
    networks:
      - net

  shard03-b:
    image: mongo
    container_name: shard03-b
    command: mongod --port 27017 --shardsvr --replSet rs-shard-03
    volumes:
      - ./scripts:/scripts
      - data_shard03-b:/data/db
    ports:
      - 27029:27017
    networks:
      - net

  shard03-c:
    image: mongo
    container_name: shard03-c
    command: mongod --port 27017 --shardsvr --replSet rs-shard-03
    volumes:
      - ./scripts:/scripts
      - data_shard03-c:/data/db
    ports:
      - 27030:27017
    networks:
      - net

  jupyterlab:
    image: andreper/jupyterlab:2.1.4-spark-3.0.0
    container_name: jupyterlab
    ports:
      - 8888:8888
    volumes:
      - ./spark-lab/:/opt/workspace/
    networks:
      - net

volumes:
  hadoop_namenode:
  hadoop_datanode1:
  hadoop_datanode2:
  hadoop_datanode3:
  hadoop_historyserver:
  data_router01:
  data_router02:
  data_configsvr01:
  data_configsvr02:
  data_configsvr03:
  data_shard01-a:
  data_shard01-b:
  data_shard01-c:
  data_shard02-a:
  data_shard02-b:
  data_shard02-c:
  data_shard03-a:
  data_shard03-b:
  data_shard03-c:

networks:
  net:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.16.0.0/24
